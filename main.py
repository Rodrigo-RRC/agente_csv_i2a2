# main.py

# 1. Importa√ß√µes para o agente de linguagem e vari√°veis de ambiente

from langchain_community.chat_models import ChatOpenAI
from langchain.schema import HumanMessage
from dotenv import load_dotenv
import os


# 2. Importa√ß√µes dos m√≥dulos internos do projeto

from agente_inteligente.ler_csv import ler_csvs_notas
from agente_inteligente.filtros import filtrar_por_estado, filtrar_por_municipio


# 3. Carrega a chave da OpenAI do arquivo .env

load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# 4. L√™ os arquivos CSV (cabecalho e itens)

df_cabecalho, df_itens = ler_csvs_notas()



# 5. Apresenta uma pr√©via dos dados

print("\nüìÑ Amostra do cabe√ßalho original:")
print(df_cabecalho.head())
print("\nüìå Atributos dispon√≠veis no DataFrame:")
for coluna in df_cabecalho.columns:
    print(" ‚îî‚îÄ", coluna)


# 6. Aplica filtro por estado (exemplo: Para√≠ba - "PB")

uf_escolhida = "PB"
municipio_escolhido = "JO√ÉO PESSOA"

# Aqui definimos qual coluna ser√° usada
coluna_uf = "UF DESTINAT√ÅRIO"
coluna_municipio = "MUNIC√çPIO EMITENTE"

df_filtrado_uf = filtrar_por_estado(df_cabecalho, uf_escolhida, coluna_uf)
df_filtrado_municipio = filtrar_por_municipio(df_cabecalho, municipio_escolhido, coluna_municipio)


# 7. Gera pergunta com base nos dados filtrados

quantidade = len(df_filtrado_uf)
mensagem_usuario = (
    f"Foram encontradas {quantidade} notas fiscais emitidas no munic√≠pio de {municipio_escolhido} ({uf_escolhida}). "
    "Qual a import√¢ncia de analisar essas emiss√µes por localidade?"
)


# 8. Inicializa o modelo da OpenAI

llm = ChatOpenAI(
    model_name="gpt-3.5-turbo",
    openai_api_key=api_key,
    temperature=0.3
)


# 9. Envia a pergunta e recebe a resposta
# üîß Prompt m√≠nimo para testes controlados (evita uso aleat√≥rio de tokens)

mensagem_usuario = "Responda exatamente com a palavra: Teste"
resposta = llm.invoke([HumanMessage(content=mensagem_usuario)])



# 10. Exibe a resposta do agente

print("\nüí¨ Resposta do agente:")
print(resposta.content)
